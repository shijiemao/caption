{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64ea5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import DataCollatorForSeq2Seq, AdamWeightDecay, \\\n",
    "    TFT5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f339f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\" Use tokenizer to preprocess data. \"\"\"\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    prefix = \"summarize: \"\n",
    "\n",
    "    inputs = [prefix + doc for doc in examples[\"string\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"label\"], max_length=80, truncation=True)\n",
    "    print(labels)\n",
    "    #model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def download_and_preprocess_data(dataset):\n",
    "    \"\"\" Load dataset from HuggingFace and preprocess. \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Tokenized using preprocess_function\n",
    "    tokenized_news = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    return tokenized_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4c3146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\",from_pt = True)\n",
    "\n",
    "optimizer = AdamWeightDecay(\n",
    "    learning_rate=2e-5, \n",
    "    weight_decay_rate=0.01\n",
    ")\n",
    "\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fb4ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"test.xlsx\")\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "014486f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['string', 'label'],\n",
       "    num_rows: 122\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbfe8924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd73e7dfd7d34fc497f9b0829da30e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28165\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\28165\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3578: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-13abff46c364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_and_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-a5a8b791abf3>\u001b[0m in \u001b[0;36mdownload_and_preprocess_data\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Tokenized using preprocess_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtokenized_news\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenized_news\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnews_ds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2825\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2826\u001b[1;33m             return self._map_single(\n\u001b[0m\u001b[0;32m   2827\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Dataset\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;31m# re-apply format to the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;31m# Call actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[1;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[0;32m   3245\u001b[0m                         )  # Something simpler?\n\u001b[0;32m   3246\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3247\u001b[1;33m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[0;32m   3248\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3249\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3122\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3123\u001b[1;33m             \u001b[0mprocessed_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3125\u001b[0m                 processed_inputs = {\n",
      "\u001b[1;32m<ipython-input-56-a5a8b791abf3>\u001b[0m in \u001b[0;36mpreprocess_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_target_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#model_inputs[\"labels\"] = labels[\"input_ids\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys_to_format\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0aed1c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80785fdaa2144d6856d21f5fe8474f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[71, 4210, 11, 7295, 13, 149, 16981, 2373, 1], [3, 9, 9251, 13, 315, 2284, 21, 16981, 1], [7295, 13, 572, 8, 5796, 19, 1692, 1], [3, 9, 13005, 344, 572, 8, 5431, 19, 1692, 11, 572, 8, 5796, 19, 1692, 1], [7295, 13, 572, 8, 1997, 19, 4459, 1], [3, 9, 4903, 13, 3, 9, 2647, 3767, 15, 1], [8, 7796, 11, 6900, 13, 3, 9, 2647, 3767, 15, 1], [46, 7295, 13, 149, 3, 9, 2647, 3767, 15, 3, 89, 4664, 1], [46, 7295, 13, 572, 2647, 3767, 15, 7, 33, 19963, 400, 17, 15, 1], [8, 10364, 13, 3, 9, 2647, 3767, 15, 1], [433, 13, 31638, 1], [570, 13, 3379, 1], [4903, 13, 3, 9, 9753, 1], [16726, 13, 753, 13, 3, 9, 810, 1], [10005, 13, 8, 810, 1], [18070, 257, 13, 97, 12, 11091, 3, 9, 4340, 1], [433, 13, 8416, 6126, 6373, 1], [9624, 122, 127, 1707, 13, 3652, 1], [9624, 122, 127, 1707, 13, 5492, 77, 257, 1308, 1], [3, 9, 4210, 13, 3, 9, 1994, 1], [46, 4332, 27866, 53, 13, 8, 16813, 13, 8, 5447, 152, 4716, 1], [16726, 13, 1128, 1], [16726, 13, 753, 13, 20818, 3, 354, 83, 23, 9, 1], [46, 677, 13, 3, 9, 6571, 32, 1], [46, 5464, 581, 7140, 4650, 7, 1], [13005, 13, 4109, 11, 7140, 4650, 7, 1], [3, 9, 4993, 13, 7140, 4650, 7, 11, 26229, 1], [7295, 13, 3, 9, 7140, 4650, 31, 7, 6637, 1], [46, 7295, 13, 572, 7869, 3, 75, 19, 207, 1], [16726, 13, 866, 13, 7869, 3, 75, 1], [3, 9, 8109, 13, 46, 928, 2309, 1], [16726, 13, 8, 753, 13, 4484, 1], [3, 9, 4903, 13, 3, 9, 3, 16170, 15, 3533, 1], [46, 4332, 27866, 53, 13, 8, 1687, 13, 16585, 159, 3, 226, 2099, 1], [46, 10356, 13, 9541, 18, 382, 17673, 7372, 15, 11240, 1], [16726, 13, 8, 9897, 13, 3, 115, 1211, 5407, 1], [7295, 13, 572, 8, 3, 2160, 17, 1273, 2615, 8, 18344, 615, 1], [16726, 13, 753, 13, 46, 25179, 1], [13005, 344, 3157, 226, 159, 51, 11, 6639, 159, 51, 1], [15476, 13, 26010, 1], [4903, 13, 26010, 1], [10356, 13, 3946, 3, 13963, 2235, 1], [46, 4332, 27866, 53, 13, 8, 5233, 13, 8, 1657, 31421, 1], [131, 2420, 13, 572, 3, 9, 31421, 19, 3, 9, 14658, 1], [1867, 581, 3887, 3182, 42, 15, 32, 7, 1], [6900, 13, 3, 9, 1782, 3182, 3, 867, 11763, 1], [10364, 13, 3, 9, 710, 733, 1], [16726, 13, 753, 1], [1867, 30, 6063, 3, 9, 126, 951, 1], [7295, 13, 315, 2530, 7, 13, 26395, 1], [46, 677, 13, 3, 9, 3979, 1], [8, 4903, 13, 3, 9, 54, 1208, 14145, 1], [16726, 13, 753, 1], [1867, 30, 3875, 7902, 1], [16726, 13, 2912, 1], [16726, 13, 583, 13, 3, 9, 220, 26, 6454, 1], [16726, 13, 583, 13, 3, 9, 3724, 1], [5464, 21, 652, 3, 9, 3724, 1], [16726, 13, 2357, 13, 46, 1523, 3724, 2564, 1], [5464, 21, 22800, 1444, 1], [1867, 30, 271, 20917, 298, 13771, 1], [3, 15, 9456, 257, 30, 149, 21, 3, 9, 1147, 19, 1], [4210, 13, 8, 3, 15, 23, 4025, 7293, 1], [7796, 13, 2943, 579, 1], [6900, 13, 2943, 579, 1], [16726, 13, 1128, 13, 3005, 4411, 1], [16726, 13, 1128, 13, 46, 23630, 1], [131, 2420, 21, 10601, 1], [4903, 13, 8, 3, 3380, 189, 12, 2902, 1], [4993, 13, 3, 102, 63, 189, 106, 11, 3, 27578, 1], [16726, 13, 583, 13, 3, 9, 4544, 1], [1867, 30, 8708, 13, 3, 2375, 1], [16726, 13, 8, 27617, 13, 3, 9, 4544, 1], [4903, 13, 9738, 1034, 1], [433, 13, 3, 1304, 14484, 1], [25705, 13, 176, 32, 19033, 2738, 1], [27866, 53, 13, 8, 4105, 13, 3, 4911, 32, 172, 1], [4903, 13, 20513, 106, 1947, 3640, 7, 1], [6803, 13, 17531, 2029, 1947, 3640, 7, 1], [4903, 13, 8, 17247, 10638, 1], [27866, 53, 13, 8, 25372, 13, 272, 17149, 210, 1], [11978, 13, 1043, 3, 7, 3828, 15, 16, 20576, 1], [27866, 53, 13, 8, 999, 13, 15489, 651, 150, 204, 1], [25705, 13, 16754, 27461, 1], [25705, 13, 873, 1677, 15, 3, 3225, 651, 872, 1], [16726, 13, 1128, 13, 2480, 2037, 1], [28721, 13, 3, 9, 3370, 1588, 1], [16726, 13, 1128, 13, 8, 3, 21346, 53, 4383, 7071, 1], [16726, 13, 753, 13, 8, 7071, 1], [892, 13, 22306, 2379, 18896, 20037, 1], [4903, 13, 12198, 1639, 3, 1258, 210, 8735, 1], [6792, 13, 3, 12851, 7, 1], [8, 5233, 13, 8, 23997, 3, 5380, 17, 172, 1], [16726, 13, 1128, 13, 8, 17829, 15, 3, 25399, 1], [25705, 13, 3, 8805, 63, 12543, 15, 7, 1], [25705, 13, 3, 5303, 3, 122, 5982, 17, 1], [4903, 13, 29578, 1723, 1], [131, 2420, 13, 1001, 3350, 53, 29578, 1723, 1], [6803, 13, 20710, 15, 63, 1212, 9, 26, 1], [7295, 13, 20, 287, 4718, 13, 2586, 443, 16310, 1], [1137, 11, 1504, 13, 2179, 346, 7, 30, 46, 10789, 1], [433, 13, 17324, 13, 3, 9, 6722, 1], [6803, 13, 3, 9, 14330, 15, 2856, 1], [4903, 13, 8633, 122, 9, 5004, 1191, 1], [1393, 13, 1437, 1036, 1], [4903, 13, 31926, 1], [20363, 13, 31926, 1], [4903, 13, 531, 7, 9, 1], [4903, 13, 350, 102, 17, 519, 1], [4903, 13, 3, 17, 755, 1], [4903, 13, 3, 17, 755, 11, 10005, 13, 3, 17, 755, 1], [4993, 13, 205, 16702, 11, 3, 102, 63, 189, 106, 1], [16726, 13, 753, 13, 331, 2056, 1], [4903, 13, 1437, 1036, 1], [3172, 13, 8, 1254, 13, 4810, 1], [4993, 13, 6639, 159, 51, 11, 569, 159, 51, 1], [16726, 13, 97, 13, 8, 600, 4514, 122, 1], [16726, 13, 1128, 13, 6179, 3191, 17, 106, 5795, 1], [4993, 13, 7833, 11, 1437, 1036, 1], [4903, 13, 8, 4963, 13, 3, 9, 825, 1], [570, 13, 5014, 27782, 1], [4903, 13, 8, 7683, 2168, 7, 10813, 9, 6912, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['string', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 122\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_news = download_and_preprocess_data(dataset)\n",
    "tokenized_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a46f535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "      <td>f001ec5c4704938247d27a44948eebb37ae98d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Never mind cats having nine lives. A stra...</td>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "      <td>230c522854991d053fe98a718b1defa077a8efef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)If you've been following the news lately,...</td>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "      <td>4495ba8f3a340d97a9df1476f8a35502bcce1f69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "      <td>a38e72fed88684ec8d60dd5856282e999dc8c0ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)A Duke student has admitted to hanging a ...</td>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "      <td>c27cf1b136cc270023de959e7ab24638021bc43f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11485</th>\n",
       "      <td>Telecom watchdogs are to stop a rip-off that a...</td>\n",
       "      <td>Operators are charging up to 20p a minute - ev...</td>\n",
       "      <td>0ac776a4dc09ca97c136f4314fed4defb48a361a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11486</th>\n",
       "      <td>The chilling reenactment of how executions are...</td>\n",
       "      <td>Bali Nine ringleaders will face the firing squ...</td>\n",
       "      <td>fe89a6a2e28d173e5ad4c6d814c15b95aa969e3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11487</th>\n",
       "      <td>It is a week which has seen him in deep water ...</td>\n",
       "      <td>Hardy was convicted of domestic abuse against ...</td>\n",
       "      <td>ded2f535cd6ab95d11b5f4ea29bbf2b2d3c55c50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>Despite the hype surrounding its first watch, ...</td>\n",
       "      <td>Apple sold more than 61 million iPhones in the...</td>\n",
       "      <td>30ec5f280eee772a73d181bfc8514defd8026434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11489</th>\n",
       "      <td>Angus Hawley's brother has spoken of his shock...</td>\n",
       "      <td>Angus Hawley's brother said his late sibling '...</td>\n",
       "      <td>b4a1738c4a0acdf3d189264a0927005aa5b856d6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      (CNN)The Palestinian Authority officially beca...   \n",
       "1      (CNN)Never mind cats having nine lives. A stra...   \n",
       "2      (CNN)If you've been following the news lately,...   \n",
       "3      (CNN)Five Americans who were monitored for thr...   \n",
       "4      (CNN)A Duke student has admitted to hanging a ...   \n",
       "...                                                  ...   \n",
       "11485  Telecom watchdogs are to stop a rip-off that a...   \n",
       "11486  The chilling reenactment of how executions are...   \n",
       "11487  It is a week which has seen him in deep water ...   \n",
       "11488  Despite the hype surrounding its first watch, ...   \n",
       "11489  Angus Hawley's brother has spoken of his shock...   \n",
       "\n",
       "                                              highlights  \\\n",
       "0      Membership gives the ICC jurisdiction over all...   \n",
       "1      Theia, a bully breed mix, was apparently hit b...   \n",
       "2      Mohammad Javad Zarif has spent more time with ...   \n",
       "3      17 Americans were exposed to the Ebola virus w...   \n",
       "4      Student is no longer on Duke University campus...   \n",
       "...                                                  ...   \n",
       "11485  Operators are charging up to 20p a minute - ev...   \n",
       "11486  Bali Nine ringleaders will face the firing squ...   \n",
       "11487  Hardy was convicted of domestic abuse against ...   \n",
       "11488  Apple sold more than 61 million iPhones in the...   \n",
       "11489  Angus Hawley's brother said his late sibling '...   \n",
       "\n",
       "                                             id  \n",
       "0      f001ec5c4704938247d27a44948eebb37ae98d01  \n",
       "1      230c522854991d053fe98a718b1defa077a8efef  \n",
       "2      4495ba8f3a340d97a9df1476f8a35502bcce1f69  \n",
       "3      a38e72fed88684ec8d60dd5856282e999dc8c0ca  \n",
       "4      c27cf1b136cc270023de959e7ab24638021bc43f  \n",
       "...                                         ...  \n",
       "11485  0ac776a4dc09ca97c136f4314fed4defb48a361a  \n",
       "11486  fe89a6a2e28d173e5ad4c6d814c15b95aa969e3f  \n",
       "11487  ded2f535cd6ab95d11b5f4ea29bbf2b2d3c55c50  \n",
       "11488  30ec5f280eee772a73d181bfc8514defd8026434  \n",
       "11489  b4a1738c4a0acdf3d189264a0927005aa5b856d6  \n",
       "\n",
       "[11490 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8b953df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pandas = ds.to_pandas()\n",
    "df_pandas = tokenized_news.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "525c0cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id'],\n",
       "    num_rows: 11490\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04bba303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)The Palestinian Authority officially beca...</td>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "      <td>f001ec5c4704938247d27a44948eebb37ae98d01</td>\n",
       "      <td>[21603, 10, 41, 254, 17235, 61, 634, 10748, 92...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[19428, 1527, 8, 3, 24291, 10185, 147, 3, 1255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Never mind cats having nine lives. A stra...</td>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "      <td>230c522854991d053fe98a718b1defa077a8efef</td>\n",
       "      <td>[21603, 10, 41, 254, 17235, 61, 567, 3258, 809...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[37, 23, 9, 6, 3, 9, 8434, 63, 8885, 2153, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)If you've been following the news lately,...</td>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "      <td>4495ba8f3a340d97a9df1476f8a35502bcce1f69</td>\n",
       "      <td>[21603, 10, 41, 254, 17235, 61, 5801, 25, 31, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1290, 1483, 11374, 10318, 26, 24374, 99, 65, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Five Americans who were monitored for thr...</td>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "      <td>a38e72fed88684ec8d60dd5856282e999dc8c0ca</td>\n",
       "      <td>[21603, 10, 41, 254, 17235, 61, 371, 757, 5452...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1003, 5452, 130, 6666, 12, 8, 262, 4243, 9, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)A Duke student has admitted to hanging a ...</td>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "      <td>c27cf1b136cc270023de959e7ab24638021bc43f</td>\n",
       "      <td>[21603, 10, 41, 254, 17235, 61, 188, 15090, 12...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6341, 19, 150, 1200, 30, 15090, 636, 4730, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11485</th>\n",
       "      <td>Telecom watchdogs are to stop a rip-off that a...</td>\n",
       "      <td>Operators are charging up to 20p a minute - ev...</td>\n",
       "      <td>0ac776a4dc09ca97c136f4314fed4defb48a361a</td>\n",
       "      <td>[21603, 10, 7338, 287, 1605, 10169, 7, 33, 12,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[25667, 7, 33, 10871, 95, 12, 460, 102, 3, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11486</th>\n",
       "      <td>The chilling reenactment of how executions are...</td>\n",
       "      <td>Bali Nine ringleaders will face the firing squ...</td>\n",
       "      <td>fe89a6a2e28d173e5ad4c6d814c15b95aa969e3f</td>\n",
       "      <td>[21603, 10, 37, 10191, 53, 3, 60, 35, 2708, 29...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[20241, 19636, 3, 1007, 22900, 7, 56, 522, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11487</th>\n",
       "      <td>It is a week which has seen him in deep water ...</td>\n",
       "      <td>Hardy was convicted of domestic abuse against ...</td>\n",
       "      <td>ded2f535cd6ab95d11b5f4ea29bbf2b2d3c55c50</td>\n",
       "      <td>[21603, 10, 94, 19, 3, 9, 471, 84, 65, 894, 37...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6424, 63, 47, 3, 21217, 13, 4422, 5384, 581, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>Despite the hype surrounding its first watch, ...</td>\n",
       "      <td>Apple sold more than 61 million iPhones in the...</td>\n",
       "      <td>30ec5f280eee772a73d181bfc8514defd8026434</td>\n",
       "      <td>[21603, 10, 3, 4868, 8, 22980, 3825, 165, 166,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2184, 1916, 72, 145, 3, 4241, 770, 3146, 7, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11489</th>\n",
       "      <td>Angus Hawley's brother has spoken of his shock...</td>\n",
       "      <td>Angus Hawley's brother said his late sibling '...</td>\n",
       "      <td>b4a1738c4a0acdf3d189264a0927005aa5b856d6</td>\n",
       "      <td>[21603, 10, 3, 8365, 302, 1626, 210, 1306, 31,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 8365, 302, 1626, 210, 1306, 31, 7, 4284, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11490 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      (CNN)The Palestinian Authority officially beca...   \n",
       "1      (CNN)Never mind cats having nine lives. A stra...   \n",
       "2      (CNN)If you've been following the news lately,...   \n",
       "3      (CNN)Five Americans who were monitored for thr...   \n",
       "4      (CNN)A Duke student has admitted to hanging a ...   \n",
       "...                                                  ...   \n",
       "11485  Telecom watchdogs are to stop a rip-off that a...   \n",
       "11486  The chilling reenactment of how executions are...   \n",
       "11487  It is a week which has seen him in deep water ...   \n",
       "11488  Despite the hype surrounding its first watch, ...   \n",
       "11489  Angus Hawley's brother has spoken of his shock...   \n",
       "\n",
       "                                              highlights  \\\n",
       "0      Membership gives the ICC jurisdiction over all...   \n",
       "1      Theia, a bully breed mix, was apparently hit b...   \n",
       "2      Mohammad Javad Zarif has spent more time with ...   \n",
       "3      17 Americans were exposed to the Ebola virus w...   \n",
       "4      Student is no longer on Duke University campus...   \n",
       "...                                                  ...   \n",
       "11485  Operators are charging up to 20p a minute - ev...   \n",
       "11486  Bali Nine ringleaders will face the firing squ...   \n",
       "11487  Hardy was convicted of domestic abuse against ...   \n",
       "11488  Apple sold more than 61 million iPhones in the...   \n",
       "11489  Angus Hawley's brother said his late sibling '...   \n",
       "\n",
       "                                             id  \\\n",
       "0      f001ec5c4704938247d27a44948eebb37ae98d01   \n",
       "1      230c522854991d053fe98a718b1defa077a8efef   \n",
       "2      4495ba8f3a340d97a9df1476f8a35502bcce1f69   \n",
       "3      a38e72fed88684ec8d60dd5856282e999dc8c0ca   \n",
       "4      c27cf1b136cc270023de959e7ab24638021bc43f   \n",
       "...                                         ...   \n",
       "11485  0ac776a4dc09ca97c136f4314fed4defb48a361a   \n",
       "11486  fe89a6a2e28d173e5ad4c6d814c15b95aa969e3f   \n",
       "11487  ded2f535cd6ab95d11b5f4ea29bbf2b2d3c55c50   \n",
       "11488  30ec5f280eee772a73d181bfc8514defd8026434   \n",
       "11489  b4a1738c4a0acdf3d189264a0927005aa5b856d6   \n",
       "\n",
       "                                               input_ids  \\\n",
       "0      [21603, 10, 41, 254, 17235, 61, 634, 10748, 92...   \n",
       "1      [21603, 10, 41, 254, 17235, 61, 567, 3258, 809...   \n",
       "2      [21603, 10, 41, 254, 17235, 61, 5801, 25, 31, ...   \n",
       "3      [21603, 10, 41, 254, 17235, 61, 371, 757, 5452...   \n",
       "4      [21603, 10, 41, 254, 17235, 61, 188, 15090, 12...   \n",
       "...                                                  ...   \n",
       "11485  [21603, 10, 7338, 287, 1605, 10169, 7, 33, 12,...   \n",
       "11486  [21603, 10, 37, 10191, 53, 3, 60, 35, 2708, 29...   \n",
       "11487  [21603, 10, 94, 19, 3, 9, 471, 84, 65, 894, 37...   \n",
       "11488  [21603, 10, 3, 4868, 8, 22980, 3825, 165, 166,...   \n",
       "11489  [21603, 10, 3, 8365, 302, 1626, 210, 1306, 31,...   \n",
       "\n",
       "                                          attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "11485  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11486  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11487  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11488  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11489  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                  labels  \n",
       "0      [19428, 1527, 8, 3, 24291, 10185, 147, 3, 1255...  \n",
       "1      [37, 23, 9, 6, 3, 9, 8434, 63, 8885, 2153, 6, ...  \n",
       "2      [1290, 1483, 11374, 10318, 26, 24374, 99, 65, ...  \n",
       "3      [1003, 5452, 130, 6666, 12, 8, 262, 4243, 9, 6...  \n",
       "4      [6341, 19, 150, 1200, 30, 15090, 636, 4730, 11...  \n",
       "...                                                  ...  \n",
       "11485  [25667, 7, 33, 10871, 95, 12, 460, 102, 3, 9, ...  \n",
       "11486  [20241, 19636, 3, 1007, 22900, 7, 56, 522, 8, ...  \n",
       "11487  [6424, 63, 47, 3, 21217, 13, 4422, 5384, 581, ...  \n",
       "11488  [2184, 1916, 72, 145, 3, 4241, 770, 3146, 7, 1...  \n",
       "11489  [3, 8365, 302, 1626, 210, 1306, 31, 7, 4284, 2...  \n",
       "\n",
       "[11490 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f25c521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id'],\n",
       "    num_rows: 11490\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b483617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tokenized_news.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f23c97f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(metric, pred, actual):\n",
    "    \"\"\" Compute the model's rouge performance on an instance. \"\"\"\n",
    "\n",
    "    metric.add(predictions=pred, references=actual)\n",
    "    final_score = metric.compute()\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4c2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 100\n",
      "Round: 200\n",
      "Round: 300\n",
      "Round: 400\n",
      "Round: 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-dd80fbf68f0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     pred = model.generate(\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m         )\n\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m         return self._generate_beam_search(\n\u001b[0m\u001b[0;32m    944\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[0mcur_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36m_generate_beam_search\u001b[1;34m(self, input_ids, cur_len, max_length, min_length, do_sample, early_stopping, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size, bad_words_ids, pad_token_id, eos_token_id, batch_size, num_return_sequences, length_penalty, num_beams, vocab_size, encoder_outputs, attention_mask, use_cache, forced_bos_token_id, forced_eos_token_id, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     banned_tokens_indices_mask.append(\n\u001b[1;32m-> 1113\u001b[1;33m                         \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m                     )\n\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     banned_tokens_indices_mask.append(\n\u001b[1;32m-> 1113\u001b[1;33m                         \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m                     )\n\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric = load_metric('rouge')\n",
    "result = [[] for x in range(3)]\n",
    "\n",
    "cnt = 0\n",
    "for item in test_ds:\n",
    "    article = item['input_ids']\n",
    "    actual = item['labels']\n",
    "    \n",
    "    pred = model.generate(\n",
    "        do_sample=True,\n",
    "        input_ids=article,\n",
    "        # min_length=56,\n",
    "        max_length=80,\n",
    "        temperature=0.8, \n",
    "        top_k=45,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    rouge_score = compute_metrics(metric, pred, actual)\n",
    "    rouge1 = 100 * rouge_score['rouge1'][1][2]\n",
    "    rouge2 = 100 * rouge_score['rouge2'][1][2]\n",
    "    rougeL = 100 * rouge_score['rougeL'][1][2]\n",
    "\n",
    "    cnt += 1 \n",
    "    if cnt % 25 == 0:\n",
    "        print(f'Round: {cnt * 4}')\n",
    "\n",
    "    result[0].append(rouge1)\n",
    "    result[1].append(rouge2)\n",
    "    result[2].append(rougeL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf7e37bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.30434782608695,\n",
       " 45.86206896551724,\n",
       " 41.9047619047619,\n",
       " 30.0632911392405,\n",
       " 34.66666666666667,\n",
       " 37.919463087248324,\n",
       " 33.45323741007194,\n",
       " 38.666666666666664,\n",
       " 37.85714285714286,\n",
       " 35.815602836879435,\n",
       " 32.857142857142854,\n",
       " 31.967213114754095,\n",
       " 36.394557823129254,\n",
       " 35.56338028169014,\n",
       " 40.789473684210535,\n",
       " 36.61971830985915,\n",
       " 40.26845637583892,\n",
       " 40.833333333333336,\n",
       " 33.55263157894737,\n",
       " 38.16793893129771,\n",
       " 40.0,\n",
       " 35.416666666666664,\n",
       " 31.25,\n",
       " 29.411764705882355,\n",
       " 33.33333333333333,\n",
       " 37.5,\n",
       " 34.96503496503497,\n",
       " 34.10852713178294,\n",
       " 32.16783216783217,\n",
       " 42.857142857142854,\n",
       " 33.56164383561644,\n",
       " 30.47945205479452,\n",
       " 35.15625000000001,\n",
       " 35.338345864661655,\n",
       " 39.310344827586206,\n",
       " 37.03703703703703,\n",
       " 28.47682119205298,\n",
       " 36.59420289855072,\n",
       " 38.43283582089552,\n",
       " 30.41666666666667,\n",
       " 36.56716417910447,\n",
       " 36.0,\n",
       " 30.14705882352941,\n",
       " 44.26229508196722,\n",
       " 33.587786259541986,\n",
       " 32.22222222222222,\n",
       " 33.44594594594595,\n",
       " 33.54430379746836,\n",
       " 34.0625,\n",
       " 30.718954248366014,\n",
       " 35.08064516129032,\n",
       " 29.78723404255319,\n",
       " 34.751773049645394,\n",
       " 38.65248226950355,\n",
       " 34.93589743589743,\n",
       " 35.12658227848101,\n",
       " 37.49999999999999,\n",
       " 41.91176470588235,\n",
       " 36.95652173913044,\n",
       " 39.77272727272727,\n",
       " 47.810218978102185,\n",
       " 34.070796460176986,\n",
       " 34.172661870503596,\n",
       " 36.84210526315789,\n",
       " 31.751824817518248,\n",
       " 43.83116883116883,\n",
       " 39.23611111111111,\n",
       " 38.888888888888886,\n",
       " 38.93129770992367,\n",
       " 37.77777777777778,\n",
       " 35.984848484848484,\n",
       " 32.35294117647059,\n",
       " 35.625,\n",
       " 33.739837398373986,\n",
       " 35.08064516129033,\n",
       " 26.89393939393939,\n",
       " 41.08527131782946,\n",
       " 40.55944055944056,\n",
       " 36.267605633802816,\n",
       " 38.983050847457626,\n",
       " 44.3089430894309,\n",
       " 32.41379310344827,\n",
       " 42.405063291139236,\n",
       " 36.16352201257862,\n",
       " 32.945736434108525,\n",
       " 37.857142857142854,\n",
       " 40.234375,\n",
       " 26.923076923076927,\n",
       " 31.944444444444443,\n",
       " 36.91588785046729,\n",
       " 41.791044776119406,\n",
       " 36.940298507462686,\n",
       " 40.06849315068492,\n",
       " 34.14634146341463,\n",
       " 36.971830985915496,\n",
       " 37.8125,\n",
       " 36.51315789473684,\n",
       " 39.28571428571429,\n",
       " 33.21917808219178,\n",
       " 34.516129032258064,\n",
       " 39.93506493506494,\n",
       " 27.814569536423843,\n",
       " 25.524475524475527,\n",
       " 35.51724137931034,\n",
       " 24.060150375939852,\n",
       " 46.21212121212121,\n",
       " 40.2027027027027,\n",
       " 38.33333333333333,\n",
       " 33.33333333333333,\n",
       " 42.53246753246753,\n",
       " 40.0,\n",
       " 36.82432432432432,\n",
       " 38.93129770992366,\n",
       " 32.01754385964912,\n",
       " 36.496350364963504,\n",
       " 34.92063492063492,\n",
       " 28.525641025641026,\n",
       " 31.329113924050638,\n",
       " 31.6,\n",
       " 35.24590163934426,\n",
       " 36.15384615384616,\n",
       " 32.692307692307686,\n",
       " 32.846715328467155,\n",
       " 45.77922077922078,\n",
       " 31.59722222222222,\n",
       " 36.09022556390977,\n",
       " 43.359375,\n",
       " 37.596899224806194,\n",
       " 34.121621621621614,\n",
       " 36.25,\n",
       " 44.907407407407405,\n",
       " 39.90384615384615,\n",
       " 28.014184397163117,\n",
       " 31.007751937984494,\n",
       " 38.333333333333336,\n",
       " 36.46616541353383,\n",
       " 34.66666666666667,\n",
       " 26.22950819672131,\n",
       " 30.844155844155846,\n",
       " 33.47457627118644,\n",
       " 37.943262411347526]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "782c6ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.545454545454547,\n",
       " 20.41522491349481,\n",
       " 20.095693779904305,\n",
       " 10.158730158730158,\n",
       " 14.381270903010035,\n",
       " 15.151515151515149,\n",
       " 13.718411552346572,\n",
       " 19.732441471571903,\n",
       " 16.48745519713262,\n",
       " 13.523131672597863,\n",
       " 14.695340501792115,\n",
       " 13.991769547325102,\n",
       " 17.064846416382252,\n",
       " 15.547703180212014,\n",
       " 16.5016501650165,\n",
       " 14.13427561837456,\n",
       " 22.22222222222222,\n",
       " 19.246861924686193,\n",
       " 12.871287128712872,\n",
       " 21.455938697318008,\n",
       " 17.573221757322173,\n",
       " 14.634146341463413,\n",
       " 11.808118081180812,\n",
       " 12.236286919831224,\n",
       " 13.240418118466902,\n",
       " 11.808118081180814,\n",
       " 16.49122807017544,\n",
       " 11.673151750972762,\n",
       " 11.929824561403509,\n",
       " 25.80645161290323,\n",
       " 10.996563573883163,\n",
       " 12.371134020618555,\n",
       " 16.470588235294116,\n",
       " 14.716981132075471,\n",
       " 19.031141868512112,\n",
       " 14.869888475836431,\n",
       " 9.302325581395348,\n",
       " 14.181818181818182,\n",
       " 11.985018726591761,\n",
       " 11.297071129707113,\n",
       " 17.602996254681642,\n",
       " 10.702341137123746,\n",
       " 13.284132841328415,\n",
       " 21.39917695473251,\n",
       " 11.49425287356322,\n",
       " 12.267657992565056,\n",
       " 11.525423728813559,\n",
       " 14.285714285714288,\n",
       " 13.793103448275861,\n",
       " 9.508196721311476,\n",
       " 14.574898785425102,\n",
       " 8.896797153024913,\n",
       " 17.08185053380783,\n",
       " 17.437722419928825,\n",
       " 11.254019292604502,\n",
       " 13.333333333333334,\n",
       " 16.605166051660518,\n",
       " 23.985239852398525,\n",
       " 17.81818181818182,\n",
       " 18.631178707224336,\n",
       " 26.73992673992674,\n",
       " 12.444444444444445,\n",
       " 12.996389891696753,\n",
       " 16.226415094339625,\n",
       " 12.087912087912086,\n",
       " 18.241042345276874,\n",
       " 21.254355400696863,\n",
       " 14.634146341463413,\n",
       " 14.559386973180077,\n",
       " 20.817843866171,\n",
       " 16.34980988593156,\n",
       " 10.70110701107011,\n",
       " 17.86833855799373,\n",
       " 12.244897959183673,\n",
       " 14.979757085020243,\n",
       " 7.984790874524713,\n",
       " 16.731517509727624,\n",
       " 24.912280701754387,\n",
       " 18.374558303886925,\n",
       " 17.872340425531917,\n",
       " 21.632653061224488,\n",
       " 11.76470588235294,\n",
       " 19.365079365079364,\n",
       " 15.457413249211355,\n",
       " 12.840466926070041,\n",
       " 20.43010752688172,\n",
       " 16.862745098039213,\n",
       " 10.877192982456139,\n",
       " 14.883720930232558,\n",
       " 14.084507042253522,\n",
       " 20.97378277153558,\n",
       " 13.483146067415733,\n",
       " 19.587628865979383,\n",
       " 16.3265306122449,\n",
       " 21.201413427561842,\n",
       " 13.793103448275861,\n",
       " 15.841584158415845,\n",
       " 16.334661354581673,\n",
       " 12.371134020618557,\n",
       " 13.26860841423948,\n",
       " 16.286644951140065,\n",
       " 11.960132890365447,\n",
       " 9.12280701754386,\n",
       " 13.14878892733564,\n",
       " 9.81132075471698,\n",
       " 21.292775665399237,\n",
       " 17.966101694915253,\n",
       " 18.729096989966557,\n",
       " 11.149825783972126,\n",
       " 20.52117263843648,\n",
       " 15.613382899628256,\n",
       " 15.254237288135593,\n",
       " 18.773946360153257,\n",
       " 13.656387665198238,\n",
       " 16.117216117216117,\n",
       " 15.936254980079678,\n",
       " 8.681672025723474,\n",
       " 12.063492063492061,\n",
       " 14.859437751004018,\n",
       " 14.40329218106996,\n",
       " 17.760617760617762,\n",
       " 9.32475884244373,\n",
       " 11.355311355311354,\n",
       " 27.687296416938107,\n",
       " 13.240418118466899,\n",
       " 18.49056603773585,\n",
       " 23.92156862745098,\n",
       " 16.731517509727624,\n",
       " 14.576271186440678,\n",
       " 13.389121338912135,\n",
       " 23.25581395348837,\n",
       " 18.84057971014493,\n",
       " 8.89679715302491,\n",
       " 11.673151750972764,\n",
       " 18.410041841004183,\n",
       " 14.716981132075475,\n",
       " 16.722408026755854,\n",
       " 11.111111111111112,\n",
       " 9.446254071661238,\n",
       " 15.319148936170212,\n",
       " 17.437722419928825]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff0a3b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.72463768115941,\n",
       " 25.517241379310345,\n",
       " 30.0,\n",
       " 17.721518987341774,\n",
       " 20.0,\n",
       " 23.154362416107382,\n",
       " 18.345323741007196,\n",
       " 27.666666666666668,\n",
       " 25.35714285714285,\n",
       " 20.921985815602838,\n",
       " 21.428571428571427,\n",
       " 23.36065573770492,\n",
       " 23.46938775510204,\n",
       " 22.887323943661972,\n",
       " 24.013157894736842,\n",
       " 22.535211267605636,\n",
       " 28.859060402684566,\n",
       " 30.000000000000004,\n",
       " 22.697368421052634,\n",
       " 28.24427480916031,\n",
       " 28.333333333333332,\n",
       " 20.833333333333336,\n",
       " 19.48529411764706,\n",
       " 19.327731092436974,\n",
       " 18.75,\n",
       " 19.485294117647058,\n",
       " 24.475524475524477,\n",
       " 20.542635658914726,\n",
       " 19.23076923076923,\n",
       " 30.00000000000001,\n",
       " 18.835616438356162,\n",
       " 19.178082191780824,\n",
       " 21.875,\n",
       " 21.428571428571427,\n",
       " 27.241379310344826,\n",
       " 21.48148148148148,\n",
       " 16.887417218543042,\n",
       " 22.10144927536232,\n",
       " 20.895522388059703,\n",
       " 18.750000000000004,\n",
       " 19.776119402985078,\n",
       " 19.666666666666668,\n",
       " 19.485294117647058,\n",
       " 27.04918032786885,\n",
       " 20.229007633587788,\n",
       " 20.370370370370374,\n",
       " 17.905405405405407,\n",
       " 22.468354430379744,\n",
       " 18.75,\n",
       " 17.64705882352941,\n",
       " 20.967741935483872,\n",
       " 17.375886524822697,\n",
       " 20.921985815602838,\n",
       " 25.17730496453901,\n",
       " 18.26923076923077,\n",
       " 18.987341772151904,\n",
       " 22.794117647058826,\n",
       " 32.720588235294116,\n",
       " 22.82608695652174,\n",
       " 25.37878787878788,\n",
       " 31.02189781021898,\n",
       " 20.353982300884955,\n",
       " 20.863309352517984,\n",
       " 22.18045112781955,\n",
       " 20.802919708029197,\n",
       " 26.623376623376622,\n",
       " 27.430555555555557,\n",
       " 22.569444444444446,\n",
       " 23.282442748091604,\n",
       " 26.296296296296294,\n",
       " 20.833333333333332,\n",
       " 18.749999999999996,\n",
       " 21.875,\n",
       " 21.95121951219512,\n",
       " 21.370967741935484,\n",
       " 16.28787878787879,\n",
       " 26.744186046511626,\n",
       " 31.118881118881113,\n",
       " 24.295774647887324,\n",
       " 23.728813559322035,\n",
       " 28.455284552845534,\n",
       " 18.620689655172416,\n",
       " 25.000000000000007,\n",
       " 21.38364779874214,\n",
       " 21.31782945736434,\n",
       " 27.142857142857142,\n",
       " 23.046874999999996,\n",
       " 15.384615384615385,\n",
       " 24.074074074074076,\n",
       " 21.962616822429904,\n",
       " 30.970149253731343,\n",
       " 22.01492537313433,\n",
       " 22.945205479452056,\n",
       " 21.95121951219512,\n",
       " 25.352112676056336,\n",
       " 20.000000000000004,\n",
       " 20.065789473684212,\n",
       " 23.015873015873016,\n",
       " 19.52054794520548,\n",
       " 20.645161290322584,\n",
       " 21.753246753246756,\n",
       " 16.556291390728475,\n",
       " 15.384615384615385,\n",
       " 18.620689655172416,\n",
       " 17.293233082706767,\n",
       " 30.681818181818183,\n",
       " 27.027027027027025,\n",
       " 23.000000000000004,\n",
       " 20.138888888888886,\n",
       " 23.376623376623375,\n",
       " 20.0,\n",
       " 20.945945945945947,\n",
       " 26.717557251908396,\n",
       " 22.368421052631582,\n",
       " 22.99270072992701,\n",
       " 23.809523809523807,\n",
       " 16.987179487179485,\n",
       " 16.77215189873418,\n",
       " 17.999999999999996,\n",
       " 22.131147540983605,\n",
       " 25.000000000000007,\n",
       " 17.628205128205128,\n",
       " 17.518248175182478,\n",
       " 32.79220779220779,\n",
       " 20.13888888888889,\n",
       " 28.947368421052634,\n",
       " 28.90625,\n",
       " 23.643410852713174,\n",
       " 19.594594594594593,\n",
       " 24.166666666666668,\n",
       " 30.09259259259259,\n",
       " 25.961538461538463,\n",
       " 18.439716312056742,\n",
       " 18.6046511627907,\n",
       " 25.833333333333336,\n",
       " 20.67669172932331,\n",
       " 20.666666666666668,\n",
       " 16.393442622950822,\n",
       " 15.584415584415584,\n",
       " 23.305084745762713,\n",
       " 23.404255319148938]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e4ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
