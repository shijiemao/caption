{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ea5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "question = data['Question']\n",
    "answer = data['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beec3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = []\n",
    "label = []\n",
    "\n",
    "new = []\n",
    "for i in range(len(question)):\n",
    "    if question[i] not in string:\n",
    "        \n",
    "        new_string = ','.join(new)\n",
    "        string.append(question[i])\n",
    "        label.append(new_string)\n",
    "        new = [answer[i]]\n",
    "    else:\n",
    "        new.append(answer[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3ff52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "\n",
    "d = [string, label]\n",
    "export_data = zip_longest(*d, fillvalue = '')\n",
    "with open('result.csv', 'w', encoding=\"utf-8\", newline='') as myfile:\n",
    "      wr = csv.writer(myfile)\n",
    "      wr.writerow((\"String\", \"Label\"))\n",
    "      wr.writerows(export_data)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f339f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\" Use tokenizer to preprocess data. \"\"\"\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    prefix = \"summarize: \"\n",
    "\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=80, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def download_and_preprocess_data():\n",
    "    \"\"\" Load dataset from HuggingFace and preprocess. \"\"\"\n",
    "    \n",
    "    news_ds = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "\n",
    "    # Tokenized using preprocess_function\n",
    "    tokenized_news = news_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "    return tokenized_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4c3146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a48bc8dd0d84c10a79190b9e7445921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\",from_pt = True)\n",
    "\n",
    "optimizer = AdamWeightDecay(\n",
    "    learning_rate=2e-5, \n",
    "    weight_decay_rate=0.01\n",
    ")\n",
    "\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aed1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (C:/Users/28165/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
      "Loading cached processed dataset at C:\\Users\\28165\\.cache\\huggingface\\datasets\\cnn_dailymail\\3.0.0\\3.0.0\\1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de\\cache-eba88d0ba3636bf1.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 11490\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_news = download_and_preprocess_data()\n",
    "tokenized_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa446515",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tokenized_news.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c4e31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(metric, pred, actual):\n",
    "    \"\"\" Compute the model's rouge performance on an instance. \"\"\"\n",
    "\n",
    "    metric.add(predictions=pred, references=actual)\n",
    "    final_score = metric.compute()\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9831cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 100\n",
      "Round: 200\n",
      "Round: 300\n",
      "Round: 400\n",
      "Round: 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-dd80fbf68f0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     pred = model.generate(\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m         )\n\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m         return self._generate_beam_search(\n\u001b[0m\u001b[0;32m    944\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[0mcur_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36m_generate_beam_search\u001b[1;34m(self, input_ids, cur_len, max_length, min_length, do_sample, early_stopping, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size, bad_words_ids, pad_token_id, eos_token_id, batch_size, num_return_sequences, length_penalty, num_beams, vocab_size, encoder_outputs, attention_mask, use_cache, forced_bos_token_id, forced_eos_token_id, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     banned_tokens_indices_mask.append(\n\u001b[1;32m-> 1113\u001b[1;33m                         \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m                     )\n\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     banned_tokens_indices_mask.append(\n\u001b[1;32m-> 1113\u001b[1;33m                         \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbanned_tokens_slice\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m                     )\n\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric = load_metric('rouge')\n",
    "result = [[] for x in range(3)]\n",
    "\n",
    "cnt = 0\n",
    "for item in test_ds:\n",
    "    article = item['input_ids']\n",
    "    actual = item['labels']\n",
    "    \n",
    "    pred = model.generate(\n",
    "        do_sample=True,\n",
    "        input_ids=article,\n",
    "        # min_length=56,\n",
    "        max_length=80,\n",
    "        temperature=0.8, \n",
    "        top_k=45,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    rouge_score = compute_metrics(metric, pred, actual)\n",
    "    rouge1 = 100 * rouge_score['rouge1'][1][2]\n",
    "    rouge2 = 100 * rouge_score['rouge2'][1][2]\n",
    "    rougeL = 100 * rouge_score['rougeL'][1][2]\n",
    "\n",
    "    cnt += 1 \n",
    "    if cnt % 25 == 0:\n",
    "        print(f'Round: {cnt * 4}')\n",
    "\n",
    "    result[0].append(rouge1)\n",
    "    result[1].append(rouge2)\n",
    "    result[2].append(rougeL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3c49c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.30434782608695,\n",
       " 45.86206896551724,\n",
       " 41.9047619047619,\n",
       " 30.0632911392405,\n",
       " 34.66666666666667,\n",
       " 37.919463087248324,\n",
       " 33.45323741007194,\n",
       " 38.666666666666664,\n",
       " 37.85714285714286,\n",
       " 35.815602836879435,\n",
       " 32.857142857142854,\n",
       " 31.967213114754095,\n",
       " 36.394557823129254,\n",
       " 35.56338028169014,\n",
       " 40.789473684210535,\n",
       " 36.61971830985915,\n",
       " 40.26845637583892,\n",
       " 40.833333333333336,\n",
       " 33.55263157894737,\n",
       " 38.16793893129771,\n",
       " 40.0,\n",
       " 35.416666666666664,\n",
       " 31.25,\n",
       " 29.411764705882355,\n",
       " 33.33333333333333,\n",
       " 37.5,\n",
       " 34.96503496503497,\n",
       " 34.10852713178294,\n",
       " 32.16783216783217,\n",
       " 42.857142857142854,\n",
       " 33.56164383561644,\n",
       " 30.47945205479452,\n",
       " 35.15625000000001,\n",
       " 35.338345864661655,\n",
       " 39.310344827586206,\n",
       " 37.03703703703703,\n",
       " 28.47682119205298,\n",
       " 36.59420289855072,\n",
       " 38.43283582089552,\n",
       " 30.41666666666667,\n",
       " 36.56716417910447,\n",
       " 36.0,\n",
       " 30.14705882352941,\n",
       " 44.26229508196722,\n",
       " 33.587786259541986,\n",
       " 32.22222222222222,\n",
       " 33.44594594594595,\n",
       " 33.54430379746836,\n",
       " 34.0625,\n",
       " 30.718954248366014,\n",
       " 35.08064516129032,\n",
       " 29.78723404255319,\n",
       " 34.751773049645394,\n",
       " 38.65248226950355,\n",
       " 34.93589743589743,\n",
       " 35.12658227848101,\n",
       " 37.49999999999999,\n",
       " 41.91176470588235,\n",
       " 36.95652173913044,\n",
       " 39.77272727272727,\n",
       " 47.810218978102185,\n",
       " 34.070796460176986,\n",
       " 34.172661870503596,\n",
       " 36.84210526315789,\n",
       " 31.751824817518248,\n",
       " 43.83116883116883,\n",
       " 39.23611111111111,\n",
       " 38.888888888888886,\n",
       " 38.93129770992367,\n",
       " 37.77777777777778,\n",
       " 35.984848484848484,\n",
       " 32.35294117647059,\n",
       " 35.625,\n",
       " 33.739837398373986,\n",
       " 35.08064516129033,\n",
       " 26.89393939393939,\n",
       " 41.08527131782946,\n",
       " 40.55944055944056,\n",
       " 36.267605633802816,\n",
       " 38.983050847457626,\n",
       " 44.3089430894309,\n",
       " 32.41379310344827,\n",
       " 42.405063291139236,\n",
       " 36.16352201257862,\n",
       " 32.945736434108525,\n",
       " 37.857142857142854,\n",
       " 40.234375,\n",
       " 26.923076923076927,\n",
       " 31.944444444444443,\n",
       " 36.91588785046729,\n",
       " 41.791044776119406,\n",
       " 36.940298507462686,\n",
       " 40.06849315068492,\n",
       " 34.14634146341463,\n",
       " 36.971830985915496,\n",
       " 37.8125,\n",
       " 36.51315789473684,\n",
       " 39.28571428571429,\n",
       " 33.21917808219178,\n",
       " 34.516129032258064,\n",
       " 39.93506493506494,\n",
       " 27.814569536423843,\n",
       " 25.524475524475527,\n",
       " 35.51724137931034,\n",
       " 24.060150375939852,\n",
       " 46.21212121212121,\n",
       " 40.2027027027027,\n",
       " 38.33333333333333,\n",
       " 33.33333333333333,\n",
       " 42.53246753246753,\n",
       " 40.0,\n",
       " 36.82432432432432,\n",
       " 38.93129770992366,\n",
       " 32.01754385964912,\n",
       " 36.496350364963504,\n",
       " 34.92063492063492,\n",
       " 28.525641025641026,\n",
       " 31.329113924050638,\n",
       " 31.6,\n",
       " 35.24590163934426,\n",
       " 36.15384615384616,\n",
       " 32.692307692307686,\n",
       " 32.846715328467155,\n",
       " 45.77922077922078,\n",
       " 31.59722222222222,\n",
       " 36.09022556390977,\n",
       " 43.359375,\n",
       " 37.596899224806194,\n",
       " 34.121621621621614,\n",
       " 36.25,\n",
       " 44.907407407407405,\n",
       " 39.90384615384615,\n",
       " 28.014184397163117,\n",
       " 31.007751937984494,\n",
       " 38.333333333333336,\n",
       " 36.46616541353383,\n",
       " 34.66666666666667,\n",
       " 26.22950819672131,\n",
       " 30.844155844155846,\n",
       " 33.47457627118644,\n",
       " 37.943262411347526]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58a01305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.545454545454547,\n",
       " 20.41522491349481,\n",
       " 20.095693779904305,\n",
       " 10.158730158730158,\n",
       " 14.381270903010035,\n",
       " 15.151515151515149,\n",
       " 13.718411552346572,\n",
       " 19.732441471571903,\n",
       " 16.48745519713262,\n",
       " 13.523131672597863,\n",
       " 14.695340501792115,\n",
       " 13.991769547325102,\n",
       " 17.064846416382252,\n",
       " 15.547703180212014,\n",
       " 16.5016501650165,\n",
       " 14.13427561837456,\n",
       " 22.22222222222222,\n",
       " 19.246861924686193,\n",
       " 12.871287128712872,\n",
       " 21.455938697318008,\n",
       " 17.573221757322173,\n",
       " 14.634146341463413,\n",
       " 11.808118081180812,\n",
       " 12.236286919831224,\n",
       " 13.240418118466902,\n",
       " 11.808118081180814,\n",
       " 16.49122807017544,\n",
       " 11.673151750972762,\n",
       " 11.929824561403509,\n",
       " 25.80645161290323,\n",
       " 10.996563573883163,\n",
       " 12.371134020618555,\n",
       " 16.470588235294116,\n",
       " 14.716981132075471,\n",
       " 19.031141868512112,\n",
       " 14.869888475836431,\n",
       " 9.302325581395348,\n",
       " 14.181818181818182,\n",
       " 11.985018726591761,\n",
       " 11.297071129707113,\n",
       " 17.602996254681642,\n",
       " 10.702341137123746,\n",
       " 13.284132841328415,\n",
       " 21.39917695473251,\n",
       " 11.49425287356322,\n",
       " 12.267657992565056,\n",
       " 11.525423728813559,\n",
       " 14.285714285714288,\n",
       " 13.793103448275861,\n",
       " 9.508196721311476,\n",
       " 14.574898785425102,\n",
       " 8.896797153024913,\n",
       " 17.08185053380783,\n",
       " 17.437722419928825,\n",
       " 11.254019292604502,\n",
       " 13.333333333333334,\n",
       " 16.605166051660518,\n",
       " 23.985239852398525,\n",
       " 17.81818181818182,\n",
       " 18.631178707224336,\n",
       " 26.73992673992674,\n",
       " 12.444444444444445,\n",
       " 12.996389891696753,\n",
       " 16.226415094339625,\n",
       " 12.087912087912086,\n",
       " 18.241042345276874,\n",
       " 21.254355400696863,\n",
       " 14.634146341463413,\n",
       " 14.559386973180077,\n",
       " 20.817843866171,\n",
       " 16.34980988593156,\n",
       " 10.70110701107011,\n",
       " 17.86833855799373,\n",
       " 12.244897959183673,\n",
       " 14.979757085020243,\n",
       " 7.984790874524713,\n",
       " 16.731517509727624,\n",
       " 24.912280701754387,\n",
       " 18.374558303886925,\n",
       " 17.872340425531917,\n",
       " 21.632653061224488,\n",
       " 11.76470588235294,\n",
       " 19.365079365079364,\n",
       " 15.457413249211355,\n",
       " 12.840466926070041,\n",
       " 20.43010752688172,\n",
       " 16.862745098039213,\n",
       " 10.877192982456139,\n",
       " 14.883720930232558,\n",
       " 14.084507042253522,\n",
       " 20.97378277153558,\n",
       " 13.483146067415733,\n",
       " 19.587628865979383,\n",
       " 16.3265306122449,\n",
       " 21.201413427561842,\n",
       " 13.793103448275861,\n",
       " 15.841584158415845,\n",
       " 16.334661354581673,\n",
       " 12.371134020618557,\n",
       " 13.26860841423948,\n",
       " 16.286644951140065,\n",
       " 11.960132890365447,\n",
       " 9.12280701754386,\n",
       " 13.14878892733564,\n",
       " 9.81132075471698,\n",
       " 21.292775665399237,\n",
       " 17.966101694915253,\n",
       " 18.729096989966557,\n",
       " 11.149825783972126,\n",
       " 20.52117263843648,\n",
       " 15.613382899628256,\n",
       " 15.254237288135593,\n",
       " 18.773946360153257,\n",
       " 13.656387665198238,\n",
       " 16.117216117216117,\n",
       " 15.936254980079678,\n",
       " 8.681672025723474,\n",
       " 12.063492063492061,\n",
       " 14.859437751004018,\n",
       " 14.40329218106996,\n",
       " 17.760617760617762,\n",
       " 9.32475884244373,\n",
       " 11.355311355311354,\n",
       " 27.687296416938107,\n",
       " 13.240418118466899,\n",
       " 18.49056603773585,\n",
       " 23.92156862745098,\n",
       " 16.731517509727624,\n",
       " 14.576271186440678,\n",
       " 13.389121338912135,\n",
       " 23.25581395348837,\n",
       " 18.84057971014493,\n",
       " 8.89679715302491,\n",
       " 11.673151750972764,\n",
       " 18.410041841004183,\n",
       " 14.716981132075475,\n",
       " 16.722408026755854,\n",
       " 11.111111111111112,\n",
       " 9.446254071661238,\n",
       " 15.319148936170212,\n",
       " 17.437722419928825]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38810522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.72463768115941,\n",
       " 25.517241379310345,\n",
       " 30.0,\n",
       " 17.721518987341774,\n",
       " 20.0,\n",
       " 23.154362416107382,\n",
       " 18.345323741007196,\n",
       " 27.666666666666668,\n",
       " 25.35714285714285,\n",
       " 20.921985815602838,\n",
       " 21.428571428571427,\n",
       " 23.36065573770492,\n",
       " 23.46938775510204,\n",
       " 22.887323943661972,\n",
       " 24.013157894736842,\n",
       " 22.535211267605636,\n",
       " 28.859060402684566,\n",
       " 30.000000000000004,\n",
       " 22.697368421052634,\n",
       " 28.24427480916031,\n",
       " 28.333333333333332,\n",
       " 20.833333333333336,\n",
       " 19.48529411764706,\n",
       " 19.327731092436974,\n",
       " 18.75,\n",
       " 19.485294117647058,\n",
       " 24.475524475524477,\n",
       " 20.542635658914726,\n",
       " 19.23076923076923,\n",
       " 30.00000000000001,\n",
       " 18.835616438356162,\n",
       " 19.178082191780824,\n",
       " 21.875,\n",
       " 21.428571428571427,\n",
       " 27.241379310344826,\n",
       " 21.48148148148148,\n",
       " 16.887417218543042,\n",
       " 22.10144927536232,\n",
       " 20.895522388059703,\n",
       " 18.750000000000004,\n",
       " 19.776119402985078,\n",
       " 19.666666666666668,\n",
       " 19.485294117647058,\n",
       " 27.04918032786885,\n",
       " 20.229007633587788,\n",
       " 20.370370370370374,\n",
       " 17.905405405405407,\n",
       " 22.468354430379744,\n",
       " 18.75,\n",
       " 17.64705882352941,\n",
       " 20.967741935483872,\n",
       " 17.375886524822697,\n",
       " 20.921985815602838,\n",
       " 25.17730496453901,\n",
       " 18.26923076923077,\n",
       " 18.987341772151904,\n",
       " 22.794117647058826,\n",
       " 32.720588235294116,\n",
       " 22.82608695652174,\n",
       " 25.37878787878788,\n",
       " 31.02189781021898,\n",
       " 20.353982300884955,\n",
       " 20.863309352517984,\n",
       " 22.18045112781955,\n",
       " 20.802919708029197,\n",
       " 26.623376623376622,\n",
       " 27.430555555555557,\n",
       " 22.569444444444446,\n",
       " 23.282442748091604,\n",
       " 26.296296296296294,\n",
       " 20.833333333333332,\n",
       " 18.749999999999996,\n",
       " 21.875,\n",
       " 21.95121951219512,\n",
       " 21.370967741935484,\n",
       " 16.28787878787879,\n",
       " 26.744186046511626,\n",
       " 31.118881118881113,\n",
       " 24.295774647887324,\n",
       " 23.728813559322035,\n",
       " 28.455284552845534,\n",
       " 18.620689655172416,\n",
       " 25.000000000000007,\n",
       " 21.38364779874214,\n",
       " 21.31782945736434,\n",
       " 27.142857142857142,\n",
       " 23.046874999999996,\n",
       " 15.384615384615385,\n",
       " 24.074074074074076,\n",
       " 21.962616822429904,\n",
       " 30.970149253731343,\n",
       " 22.01492537313433,\n",
       " 22.945205479452056,\n",
       " 21.95121951219512,\n",
       " 25.352112676056336,\n",
       " 20.000000000000004,\n",
       " 20.065789473684212,\n",
       " 23.015873015873016,\n",
       " 19.52054794520548,\n",
       " 20.645161290322584,\n",
       " 21.753246753246756,\n",
       " 16.556291390728475,\n",
       " 15.384615384615385,\n",
       " 18.620689655172416,\n",
       " 17.293233082706767,\n",
       " 30.681818181818183,\n",
       " 27.027027027027025,\n",
       " 23.000000000000004,\n",
       " 20.138888888888886,\n",
       " 23.376623376623375,\n",
       " 20.0,\n",
       " 20.945945945945947,\n",
       " 26.717557251908396,\n",
       " 22.368421052631582,\n",
       " 22.99270072992701,\n",
       " 23.809523809523807,\n",
       " 16.987179487179485,\n",
       " 16.77215189873418,\n",
       " 17.999999999999996,\n",
       " 22.131147540983605,\n",
       " 25.000000000000007,\n",
       " 17.628205128205128,\n",
       " 17.518248175182478,\n",
       " 32.79220779220779,\n",
       " 20.13888888888889,\n",
       " 28.947368421052634,\n",
       " 28.90625,\n",
       " 23.643410852713174,\n",
       " 19.594594594594593,\n",
       " 24.166666666666668,\n",
       " 30.09259259259259,\n",
       " 25.961538461538463,\n",
       " 18.439716312056742,\n",
       " 18.6046511627907,\n",
       " 25.833333333333336,\n",
       " 20.67669172932331,\n",
       " 20.666666666666668,\n",
       " 16.393442622950822,\n",
       " 15.584415584415584,\n",
       " 23.305084745762713,\n",
       " 23.404255319148938]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fffb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
