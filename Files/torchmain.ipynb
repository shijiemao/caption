{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7901317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#Common Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e33184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transform\n",
    "import torchtext\n",
    "from torchtext.prototype.models import T5Transform\n",
    "\n",
    "padding_idx = 0\n",
    "eos_idx = 1\n",
    "max_seq_len = 512\n",
    "t5_sp_model_path = \"https://download.pytorch.org/models/text/t5_tokenizer_base.model\"\n",
    "\n",
    "transform = T5Transform(\n",
    "    sp_model_path=t5_sp_model_path,\n",
    "    max_seq_len=max_seq_len,\n",
    "    eos_idx=eos_idx,\n",
    "    padding_idx=padding_idx,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3f5b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
       "  (encoder): T5Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "          (relative_attention_bias): Embedding(32, 12)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (6): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (7): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (8): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (9): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (10): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (11): T5EncoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm1): T5LayerNorm()\n",
       "  (dropout1): Dropout(p=0.0, inplace=False)\n",
       "  (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  (decoder): T5Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "          (relative_attention_bias): Embedding(32, 12)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (6): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (7): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (8): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (9): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (10): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (11): T5DecoderLayer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm2): T5LayerNorm()\n",
       "  (dropout3): Dropout(p=0.0, inplace=False)\n",
       "  (dropout4): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Preparation\n",
    "\n",
    "from torchtext.prototype.models import T5_BASE_GENERATION\n",
    "\n",
    "\n",
    "t5_base = T5_BASE_GENERATION\n",
    "transform = t5_base.transform()\n",
    "model = t5_base.get_model()\n",
    "model.eval()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4155e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torchtext.prototype.models import T5Model\n",
    "\n",
    "\n",
    "def beam_search(\n",
    "    beam_size: int,\n",
    "    step: int,\n",
    "    bsz: int,\n",
    "    decoder_output: Tensor,\n",
    "    decoder_tokens: Tensor,\n",
    "    scores: Tensor,\n",
    "    incomplete_sentences: Tensor,\n",
    "):\n",
    "    probs = F.log_softmax(decoder_output[:, -1], dim=-1)\n",
    "    top = torch.topk(probs, beam_size)\n",
    "\n",
    "    # N is number of sequences in decoder_tokens, L is length of sequences, B is beam_size\n",
    "    # decoder_tokens has shape (N,L) -> (N,B,L)\n",
    "    # top.indices has shape (N,B) - > (N,B,1)\n",
    "    # x has shape (N,B,L+1)\n",
    "    # note that when step == 1, N = batch_size, and when step > 1, N = batch_size * beam_size\n",
    "    x = torch.cat([decoder_tokens.unsqueeze(1).repeat(1, beam_size, 1), top.indices.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    # beams are first created for a given sequence\n",
    "    if step == 1:\n",
    "        # x has shape (batch_size, B, L+1) -> (batch_size * B, L+1)\n",
    "        # new_scores has shape (batch_size,B)\n",
    "        # incomplete_sentences has shape (batch_size * B) = (N)\n",
    "        new_decoder_tokens = x.view(-1, step + 1)\n",
    "        new_scores = top.values\n",
    "        new_incomplete_sentences = incomplete_sentences\n",
    "\n",
    "    # beams already exist, want to expand each beam into possible new tokens to add\n",
    "    # and for all expanded beams beloning to the same sequences, choose the top k\n",
    "    else:\n",
    "        # scores has shape (batch_size,B) -> (N,1) -> (N,B)\n",
    "        # top.values has shape (N,B)\n",
    "        # new_scores has shape (N,B) -> (batch_size, B^2)\n",
    "        new_scores = (scores.view(-1, 1).repeat(1, beam_size) + top.values).view(bsz, -1)\n",
    "\n",
    "        # v, i have shapes (batch_size, B)\n",
    "        v, i = torch.topk(new_scores, beam_size)\n",
    "\n",
    "        # x has shape (N,B,L+1) -> (batch_size, B, L+1)\n",
    "        # i has shape (batch_size, B) -> (batch_size, B, L+1)\n",
    "        # new_decoder_tokens has shape (batch_size, B, L+1) -> (N, L)\n",
    "        x = x.view(bsz, -1, step + 1)\n",
    "        new_decoder_tokens = x.gather(index=i.unsqueeze(-1).repeat(1, 1, step + 1), dim=1).view(-1, step + 1)\n",
    "\n",
    "        # need to update incomplete sentences in case one of the beams was kicked out\n",
    "        # y has shape (N) -> (N, 1) -> (N, B) -> (batch_size, B^2)\n",
    "        y = incomplete_sentences.unsqueeze(-1).repeat(1, beam_size).view(bsz, -1)\n",
    "\n",
    "        # now can use i to extract those beams that were selected\n",
    "        # new_incomplete_sentences has shape (batch_size, B^2) -> (batch_size, B) -> (N, 1) -> N\n",
    "        new_incomplete_sentences = y.gather(index=i, dim=1).view(bsz * beam_size, 1).squeeze(-1)\n",
    "\n",
    "        # new_scores has shape (batch_size, B)\n",
    "        new_scores = v\n",
    "\n",
    "    return new_decoder_tokens, new_scores, new_incomplete_sentences\n",
    "\n",
    "\n",
    "def generate(encoder_tokens: Tensor, eos_idx: int, model: T5Model, beam_size: int) -> Tensor:\n",
    "\n",
    "    # pass tokens through encoder\n",
    "    bsz = encoder_tokens.size(0)\n",
    "    encoder_padding_mask = encoder_tokens.eq(model.padding_idx)\n",
    "    encoder_embeddings = model.dropout1(model.token_embeddings(encoder_tokens))\n",
    "    encoder_output = model.encoder(encoder_embeddings, tgt_key_padding_mask=encoder_padding_mask)[0]\n",
    "\n",
    "    encoder_output = model.norm1(encoder_output)\n",
    "    encoder_output = model.dropout2(encoder_output)\n",
    "\n",
    "    # initialize decoder input sequence; T5 uses padding index as starter index to decoder sequence\n",
    "    decoder_tokens = torch.ones((bsz, 1), dtype=torch.long) * model.padding_idx\n",
    "    scores = torch.zeros((bsz, beam_size))\n",
    "\n",
    "    # mask to keep track of sequences for which the decoder has not produced an end-of-sequence token yet\n",
    "    incomplete_sentences = torch.ones(bsz * beam_size, dtype=torch.long)\n",
    "\n",
    "    # iteratively generate output sequence until all sequences in the batch have generated the end-of-sequence token\n",
    "    for step in range(model.config.max_seq_len):\n",
    "\n",
    "        if step == 1:\n",
    "            # duplicate and order encoder output so that each beam is treated as its own independent sequence\n",
    "            new_order = torch.arange(bsz).view(-1, 1).repeat(1, beam_size).view(-1)\n",
    "            new_order = new_order.to(encoder_tokens.device).long()\n",
    "            encoder_output = encoder_output.index_select(0, new_order)\n",
    "            encoder_padding_mask = encoder_padding_mask.index_select(0, new_order)\n",
    "\n",
    "        # causal mask and padding mask for decoder sequence\n",
    "        tgt_len = decoder_tokens.shape[1]\n",
    "        decoder_mask = torch.triu(torch.ones((tgt_len, tgt_len), dtype=torch.float64), diagonal=1).bool()\n",
    "        decoder_padding_mask = decoder_tokens.eq(model.padding_idx)\n",
    "\n",
    "        # T5 implemention uses padding idx to start sequence. Want to ignore this when masking\n",
    "        decoder_padding_mask[:, 0] = False\n",
    "\n",
    "        # pass decoder sequence through decoder\n",
    "        decoder_embeddings = model.dropout3(model.token_embeddings(decoder_tokens))\n",
    "        decoder_output = model.decoder(\n",
    "            decoder_embeddings,\n",
    "            memory=encoder_output,\n",
    "            tgt_mask=decoder_mask,\n",
    "            tgt_key_padding_mask=decoder_padding_mask,\n",
    "            memory_key_padding_mask=encoder_padding_mask,\n",
    "        )[0]\n",
    "\n",
    "        decoder_output = model.norm2(decoder_output)\n",
    "        decoder_output = model.dropout4(decoder_output)\n",
    "        decoder_output = decoder_output * (model.config.embedding_dim ** -0.5)\n",
    "        decoder_output = model.lm_head(decoder_output)\n",
    "\n",
    "        decoder_tokens, scores, incomplete_sentences = beam_search(\n",
    "            beam_size, step + 1, bsz, decoder_output, decoder_tokens, scores, incomplete_sentences\n",
    "        )\n",
    "        # ignore newest tokens for sentences that are already complete\n",
    "        decoder_tokens[:, -1] *= incomplete_sentences\n",
    "\n",
    "        # update incomplete_sentences to remove those that were just ended\n",
    "        incomplete_sentences = incomplete_sentences - (decoder_tokens[:, -1] == eos_idx).long()\n",
    "\n",
    "        # early stop if all sentences have been ended\n",
    "        if (incomplete_sentences == 0).all():\n",
    "            break\n",
    "\n",
    "    # take most likely sequence\n",
    "    decoder_tokens = decoder_tokens.view(bsz, beam_size, -1)[:, 0, :]\n",
    "    return decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f4e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "\n",
    "from functools import partial\n",
    "from torchtext.datasets import CNNDM   \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cnndm_batch_size = 5\n",
    "cnndm_datapipe = CNNDM(split=\"test\")\n",
    "task = \"summarize\"\n",
    "\n",
    "\n",
    "def apply_prefix(task, x):\n",
    "    return f\"{task}: \" + x[0], x[1]\n",
    "\n",
    "\n",
    "cnndm_datapipe = cnndm_datapipe.map(partial(apply_prefix, task))\n",
    "cnndm_datapipe = cnndm_datapipe.batch(cnndm_batch_size)\n",
    "cnndm_datapipe = cnndm_datapipe.rows2columnar([\"article\", \"abstract\"])\n",
    "cnndm_dataloader = DataLoader(cnndm_datapipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c298df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNNDM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-584f499894d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcnndm_datapipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNNDM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CNNDM' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "cnndm_datapipe = CNNDM(split=\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d133e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summarize: (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.', 'summarize: (CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That\\'s according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital. Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by a worker who took her to a vet for help. She was taken in by Moses Lake, Washington, resident Sara Mellado. \"Considering everything that she\\'s been through, she\\'s incredibly gentle and loving,\" Mellado said, according to WSU News. \"She\\'s a true miracle dog and she deserves a good life.\" Theia is only one year old but the dog\\'s brush with death did not leave her unscathed. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity -- and still requires surgery to help her breathe. The veterinary hospital\\'s Good Samaritan Fund committee awarded some money to help pay for the dog\\'s treatment, but Mellado has set up a fundraising page to help meet the remaining cost of the dog\\'s care. She\\'s also created a Facebook page to keep supporters updated. Donors have already surpassed the $10,000 target, inspired by Theia\\'s tale of survival against the odds. On the fundraising page, Mellado writes, \"She is in desperate need of extensive medical procedures to fix her nasal damage and reset her jaw. I agreed to foster her until she finally found a loving home.\" She is dedicated to making sure Theia gets the medical attention she needs, Mellado adds, and wants to \"make sure she gets placed in a family where this will never happen to her again!\" Any additional funds raised will be \"paid forward\" to help other animals. Theia is not the only animal to apparently rise from the grave in recent weeks. A cat in Tampa, Florida, found seemingly dead after he was hit by a car in January, showed up alive in a neighbor\\'s yard five days after he was buried by his owner. The cat was in bad shape, with maggots covering open wounds on his body and a ruined left eye, but remarkably survived with the help of treatment from the Humane Society.', 'summarize: (CNN)If you\\'ve been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of State John Kerry\\'s opposite number in securing a breakthrough in nuclear discussions that could lead to an end to sanctions against Iran -- if the details can be worked out in the coming weeks. And he received a hero\\'s welcome as he arrived in Iran on a sunny Friday morning. \"Long live Zarif,\" crowds chanted as his car rolled slowly down the packed street. You may well have read that he is \"polished\" and, unusually for one burdened with such weighty issues, \"jovial.\" An Internet search for \"Mohammad Javad Zarif\" and \"jovial\" yields thousands of results. He certainly has gone a long way to bring Iran in from the cold and allow it to rejoin the international community. But there are some facts about Zarif that are less well-known. Here are six: . In September 2013, Zarif tweeted \"Happy Rosh Hashanah,\" referring to the Jewish New Year. That prompted Christine Pelosi, the daughter of House Minority Leader Nancy Pelosi, to respond with a tweet of her own: \"Thanks. The New Year would be even sweeter if you would end Iran\\'s Holocaust denial, sir.\" And, perhaps to her surprise, Pelosi got a response. \"Iran never denied it,\" Zarif tweeted back. \"The man who was perceived to be denying it is now gone. Happy New Year.\" The reference was likely to former Iranian President Mahmoud Ahmadinejad, who had left office the previous month. Zarif was nominated to be foreign minister by Ahmadinejad\\'s successor, Hassan Rouhami. His foreign ministry notes, perhaps defensively, that \"due to the political and security conditions of the time, he decided to continue his education in the United States.\" That is another way of saying that he was outside the country during the demonstrations against the Shah of Iran, which began in 1977, and during the Iranian Revolution, which drove the shah from power in 1979. Zarif left the country in 1977, received his undergraduate degree from San Francisco State University in 1981, his master\\'s in international relations from the University of Denver in 1984 and his doctorate from the University of Denver in 1988. Both of his children were born in the United States. The website of the Iranian Foreign Ministry, which Zarif runs, cannot even agree with itself on when he was born. The first sentence of his official biography, perhaps in a nod to the powers that be in Tehran, says Zarif was \"born to a religious traditional family in Tehran in 1959.\" Later on the same page, however, his date of birth is listed as January 8, 1960. And the Iranian Diplomacy website says he was born in in 1961 . So he is 54, 55 or maybe even 56. Whichever, he is still considerably younger than his opposite number, Kerry, who is 71. The feds investigated him over his alleged role in controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-story building in Manhattan along with other properties to the U.S. government, did not mention Zarif\\'s name. Early in the Iranian Revolution, Zarif was among the students who took over the Iranian Consulate in San Francisco. The aim, says the website Iranian.com -- which cites Zarif\\'s memoirs, titled \"Mr. Ambassador\" -- was to expel from the consulate people who were not sufficiently Islamic. Later, the website says, Zarif went to make a similar protest at the Iranian mission to the United Nations. In response, the Iranian ambassador to the United Nations offered him a job. In fact, he has now spent more time with Kerry than any other foreign minister in the world. And that amount of quality time will only increase as the two men, with help from other foreign ministers as well, try to meet a June 30 deadline for nailing down the details of the agreement they managed to outline this week in Switzerland.', \"summarize: (CNN)Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being exposed to Ebola in West Africa have been released, a Nebraska Medicine spokesman said in an email Wednesday. One of the five had a heart-related issue on Saturday and has been discharged but hasn't left the area, Taylor Wilson wrote. The others have already gone home. They were exposed to Ebola in Sierra Leone in March, but none developed the deadly virus. They are clinicians for Partners in Health, a Boston-based aid group. They all had contact with a colleague who was diagnosed with the disease and is being treated at the National Institutes of Health in Bethesda, Maryland. As of Monday, that health care worker is in fair condition. The Centers for Disease Control and Prevention in Atlanta has said the last of 17 patients who were being monitored are expected to be released by Thursday. More than 10,000 people have died in a West African epidemic of Ebola that dates to December 2013, according to the World Health Organization. Almost all the deaths have been in Guinea, Liberia and Sierra Leone. Ebola is spread by direct contact with the bodily fluids of an infected person.\", 'summarize: (CNN)A Duke student has admitted to hanging a noose made of rope from a tree near a student union, university officials said Thursday. The prestigious private school didn\\'t identify the student, citing federal privacy laws. In a news release, it said the student was no longer on campus and will face student conduct review. The student was identified during an investigation by campus police and the office of student affairs and admitted to placing the noose on the tree early Wednesday, the university said. Officials are still trying to determine if other people were involved. Criminal investigations into the incident are ongoing as well. Students and faculty members marched Wednesday afternoon chanting \"We are not afraid. We stand together,\"  after pictures of the noose were passed around on social media. At a forum held on the steps of Duke Chapel, close to where the noose was discovered at 2 a.m., hundreds of people gathered. \"You came here for the reason that you want to say with me, \\'This is no Duke we will accept. This is no Duke we want. This is not the Duke we\\'re here to experience. And this is not the Duke we\\'re here to create,\\' \" Duke President Richard Brodhead told the crowd. The incident is one of several recent racist events to affect college students. Last month a fraternity at the University of Oklahoma had its charter removed after a video surfaced showing members using the N-word and referring to lynching in a chant. Two students were expelled. In February, a noose was hung around the neck of a statue of a famous civil rights figure at the University of Mississippi. A statement issued by Duke said there was a previous report of hate speech directed at students on campus. In the news release, the vice president for student affairs called the noose incident a \"cowardly act.\" \"To whomever committed this hateful and stupid act, I just want to say that if your intent was to create fear, it will have the opposite effect,\" Larry Moneta said Wednesday. Duke University is a private college with about 15,000 students in Durham, North Carolina. CNN\\'s Dave Alsup contributed to this report.']\n"
     ]
    }
   ],
   "source": [
    "first = next(iter(cnndm_datapipe))\n",
    "labels, features = first['article'], first['abstract']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "028fa5d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-de9820709a16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnndm_datapipe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\rows2columnar.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_datapipe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mcolumnar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlist_or_dict_row\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\grouping.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDataChunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\grouping.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_datapipe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_of_instances\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combinatorics.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchtext\\data\\datasets_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_datapipe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\fileopener.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# a subtype would cause mypy error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mget_file_binaries_from_pathnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py\u001b[0m in \u001b[0;36mget_file_binaries_from_pathnames\u001b[1;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mpathname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpathnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise TypeError(\"Expected string type for pathname, but got {}\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py\u001b[0m in \u001b[0;36mwrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         \u001b[0m_check_iterator_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    453\u001b[0m                         \u001b[1;31m# Keys should be always the same (1-1 situation) or always different (1-many) sutuation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first key somehow equal to secondary key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mrec_uuid\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlast_record_uuid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m                     fulfill_old_promises(\n\u001b[0;32m    457\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_cell_dp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_record_uuid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst_filepath_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache_uuid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\uuid.py\u001b[0m in \u001b[0;36m__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    231\u001b[0m                            if 'is_safe' in state else SafeUUID.unknown)\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUUID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list(cnndm_datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca292dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "\n",
    "FOLDER = r'C:\\Users\\28165\\caption\\data'\n",
    "datapipe = dp.iter.FileLister([FOLDER]).filter(filter_fn=  filename: filename.endswith('.csv'))\n",
    "datapipe = dp.iter.FileOpener(datapipe, mode='rt')\n",
    "datapipe = datapipe.parse_csv(delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61026e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = 10000  # total number of rows of data\n",
    "train, valid = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.5, \"valid\": 0.5}, seed=0)\n",
    "\n",
    "for x in train:  # Iterating through the training dataset\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb1ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "inputs = [[ 1,  2,  3,  4,  5],[ 2,  3,  4,  5,  6]]\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68f54451",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1728bbcc8427>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"string\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "features = data[[\"string\",\"label\"]].transpose().values.tolist()\n",
    "input = torch.tensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac4d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment classification\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "imdb_batch_size = 3\n",
    "imdb_datapipe = IMDB(split=\"test\")\n",
    "task = \"sst2 sentence\"\n",
    "labels = {\"neg\": \"negative\", \"pos\": \"positive\"}\n",
    "\n",
    "\n",
    "def process_labels(labels, x):\n",
    "    return x[1], labels[x[0]]\n",
    "\n",
    "\n",
    "imdb_datapipe = imdb_datapipe.map(partial(process_labels, labels))\n",
    "imdb_datapipe = imdb_datapipe.map(partial(apply_prefix, task))\n",
    "imdb_datapipe = imdb_datapipe.batch(imdb_batch_size)\n",
    "imdb_datapipe = imdb_datapipe.rows2columnar([\"text\", \"label\"])\n",
    "imdb_dataloader = DataLoader(imdb_datapipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8be4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation\n",
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "multi_batch_size = 5\n",
    "language_pair = (\"en\", \"de\")\n",
    "multi_datapipe = Multi30k(split=\"test\", language_pair=language_pair)\n",
    "task = \"translate English to German\"\n",
    "\n",
    "multi_datapipe = multi_datapipe.map(partial(apply_prefix, task))\n",
    "multi_datapipe = multi_datapipe.batch(multi_batch_size)\n",
    "multi_datapipe = multi_datapipe.rows2columnar([\"english\", \"german\"])\n",
    "multi_dataloader = DataLoader(multi_datapipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48ea779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(cnndm_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856215fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(cnndm_dataloader))\n",
    "input_text = batch[\"article\"]\n",
    "target = batch[\"abstract\"]\n",
    "beam_size = 3\n",
    "\n",
    "model_input = transform(input_text)\n",
    "model_output = generate(model=model, encoder_tokens=model_input, eos_idx=eos_idx, beam_size=beam_size)\n",
    "output_text = transform.decode(model_output.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85395050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4550c4145b004b564f2b936b9955585751a2c488f90c30c541e98f3539ed2149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
